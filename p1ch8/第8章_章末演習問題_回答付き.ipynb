{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章の章末演習問題\n",
    "\n",
    "※ ここではGoogle Colaraboratoryでの実行を想定しています。\n",
    "\n",
    "※ Google Colaraboratoryでbashコマンドを実行するには、命令の前に!をつけます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1]nn.Conv2dコンストラクターに、kernel_size=5で5 × 5のサイズのカーネルを渡すようにモデルを変えてください。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a この変更により、モデル内のパラメーターにはどのような影響があるでしょうか。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回答\n",
    "\n",
    "# 再現性の確保のため、事前にseedを固定します。\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 第8章のコードより\n",
    "\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):  # <2>\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:  # <3>\n",
    "            \n",
    "            outputs = model(imgs)  # <4>\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)  # <5>\n",
    "\n",
    "            optimizer.zero_grad()  # <6>\n",
    "            \n",
    "            loss.backward()  # <7>\n",
    "            \n",
    "            optimizer.step()  # <8>\n",
    "\n",
    "            loss_train += loss.item()  # <9>\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))\n",
    "            \n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "\n",
    "# Google ColaboratoryでGoogleドライブをマウントする場合\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_path = './content/drive/My Drive/[任意のパス]'\n",
    "\n",
    "# Google Colaboratory上のディスクを使用する場合\n",
    "data_path = \"../data-unversioned/p1ch7/\"\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10\n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "変更前のパラメーター数:18090\n変更後のパラメーター数:20906\n"
     ]
    }
   ],
   "source": [
    "# カーネルが大きくなったため、モデル内のパラメーター数は増加する。\n",
    "\n",
    "model = Net()\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "print(f'変更前のパラメーター数:{sum(numel_list)}')\n",
    "\n",
    "model.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=2) # 畳み込み後に出力されるテンソルと後続の線形層への入力を考慮して、\n",
    "model.conv2 = nn.Conv2d(16, 8, kernel_size=5, padding=2) # paddingも+1しています。\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "print(f'変更後のパラメーター数:{sum(numel_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b この変更は過剰適合を促進させてしまうでしょうか？それとも劣化させるでしょうか。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "kerne_size=3 の場合\n",
      "2020-12-15 23:22:52.505605 Epoch 1, Training loss 0.5646076008772395\n",
      "2020-12-15 23:23:31.919734 Epoch 10, Training loss 0.328009745782348\n",
      "2020-12-15 23:24:12.332125 Epoch 20, Training loss 0.2952318012619474\n",
      "2020-12-15 23:24:52.795821 Epoch 30, Training loss 0.2697624414210107\n",
      "2020-12-15 23:25:33.797427 Epoch 40, Training loss 0.25104503751180735\n",
      "2020-12-15 23:26:20.161050 Epoch 50, Training loss 0.23599227403949022\n",
      "2020-12-15 23:27:01.650966 Epoch 60, Training loss 0.2208448565879445\n",
      "2020-12-15 23:27:43.339019 Epoch 70, Training loss 0.20523585183367987\n",
      "2020-12-15 23:28:22.576114 Epoch 80, Training loss 0.19314802649199583\n",
      "2020-12-15 23:29:03.044518 Epoch 90, Training loss 0.1804624343184149\n",
      "2020-12-15 23:29:40.902064 Epoch 100, Training loss 0.166676272062739\n",
      "Accuracy train: 0.93\n",
      "Accuracy val: 0.88\n",
      "\n",
      "kerne_size=5 の場合\n",
      "2020-12-15 23:29:48.671002 Epoch 1, Training loss 0.5525380238226265\n",
      "2020-12-15 23:30:31.546795 Epoch 10, Training loss 0.31731592004845854\n",
      "2020-12-15 23:31:19.830195 Epoch 20, Training loss 0.2757870511739117\n",
      "2020-12-15 23:32:10.321705 Epoch 30, Training loss 0.25080791585574486\n",
      "2020-12-15 23:33:00.760274 Epoch 40, Training loss 0.22441616754053503\n",
      "2020-12-15 23:33:50.917097 Epoch 50, Training loss 0.19913963157280234\n",
      "2020-12-15 23:34:41.316438 Epoch 60, Training loss 0.17818935713760412\n",
      "2020-12-15 23:35:39.688786 Epoch 70, Training loss 0.15364477667174523\n",
      "2020-12-15 23:36:27.267145 Epoch 80, Training loss 0.1394497603415304\n",
      "2020-12-15 23:37:20.291960 Epoch 90, Training loss 0.12070531081289622\n",
      "2020-12-15 23:38:13.122454 Epoch 100, Training loss 0.10303293016685802\n",
      "Accuracy train: 0.94\n",
      "Accuracy val: 0.89\n"
     ]
    }
   ],
   "source": [
    "# 回答\n",
    "# パラメーターが増えたことにより、オーバーフィッティングする可能性が高くなります。\n",
    "\n",
    "def kernel_size_experiment(changes_kernel:bool):\n",
    "    model = Net()\n",
    "    if changes_kernel:\n",
    "        # カーネルサイズを変更する場合        \n",
    "        model.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=2)\n",
    "        model.conv2 = nn.Conv2d(16, 8, kernel_size=5, padding=2)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                               shuffle=True)\n",
    "    training_loop(\n",
    "        n_epochs = 100,\n",
    "        optimizer = optimizer,\n",
    "        model = model,\n",
    "        loss_fn = loss_fn,\n",
    "        train_loader = train_loader,\n",
    "    )\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                               shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "    validate(model, train_loader, val_loader)\n",
    "\n",
    "print('kerne_size=3 の場合')\n",
    "kernel_size_experiment(changes_kernel=False)\n",
    "print('')\n",
    "print('kerne_size=5 の場合')\n",
    "kernel_size_experiment(changes_kernel=True)\n",
    "\n",
    "# kernel_size=5 に変更したことで、Accuracyが0.1上がったため汎化性能は向上したと判断することが出来ます。\n",
    "# ただし、訓練セットのAccuracyと検証セットのAccuracyの乖離は大きくなっています。\n",
    "# つまり、オーバーフィッティングしている兆候があると考えらます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c https://pytorch.org/docs/stable/nn.html#conv2d. を読んでみましょう。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 省略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d kernel_size=(1,3) は何を行うでしょうか。説明してください。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e 上記のようなカーネルを備えたモデルはどのような振る舞いをするでしょうか。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2]鳥も飛行機も含まれていないが、モデルが95%以上の確信度で鳥も飛行機が写っていると主張するような画像を見つけることができますか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-12-15 23:38:21.800243 Epoch 1, Training loss 0.6047181861036143\n",
      "2020-12-15 23:38:59.337686 Epoch 10, Training loss 0.33143053872949757\n",
      "2020-12-15 23:39:38.478730 Epoch 20, Training loss 0.296157294302989\n",
      "2020-12-15 23:40:18.179834 Epoch 30, Training loss 0.271825486212779\n",
      "2020-12-15 23:40:56.759377 Epoch 40, Training loss 0.2529176988988925\n",
      "2020-12-15 23:41:37.956019 Epoch 50, Training loss 0.2345508227872241\n",
      "2020-12-15 23:42:18.281348 Epoch 60, Training loss 0.21824557775524772\n",
      "2020-12-15 23:42:57.349849 Epoch 70, Training loss 0.20523470402902858\n",
      "2020-12-15 23:43:38.135380 Epoch 80, Training loss 0.18932760634999365\n",
      "2020-12-15 23:44:19.098022 Epoch 90, Training loss 0.17314723869607707\n",
      "2020-12-15 23:44:58.102665 Epoch 100, Training loss 0.16250486012287202\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                        shuffle=True)\n",
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a ニュートラルな画像を手動で編集して飛行機らしくすることはできますか？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 省略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b 飛行機の画像を手動で編集し、モデルを騙して鳥の報告をさせることはできますか？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 省略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c これらのタスクは、ネットワークの容量が少ないほど簡単になりますか？それとも、大きいほど簡単になりますか？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回答\n",
    "\n",
    "# ネットワークが大きい（パラメーター数が多いほど）ほど\n",
    "# 対象物が有する様々な特徴量を捕捉できるようになるため、簡単になる。\n",
    "# ※なお、本文でも述べられているように、パラメーター数が多くなるほど、過剰適合する可能性があります。\n",
    "# 　そのため、特にタスクの難易度が簡単な場合（画像が小さかったり、単純なものである場合）、\n",
    "# 　汎化の観点からは、ネットワークが大きければ、必ず簡単になる、というわけでは\n",
    "# 　ないことに留意してください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}